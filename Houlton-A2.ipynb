{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\Xv}{\\mathbf{X}}\n",
    "\\newcommand{\\Xvh}{\\hat{\\mathbf{X}}}\n",
    "\\newcommand{\\yv}{\\mathbf{y}}\n",
    "\\newcommand{\\Yv}{\\mathbf{Y}}\n",
    "\\newcommand{\\av}{\\mathbf{a}}\n",
    "\\newcommand{\\Wv}{\\mathbf{W}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "\\newcommand{\\gv}{\\mathbf{g}}\n",
    "\\newcommand{\\Hv}{\\mathbf{H}}\n",
    "\\newcommand{\\dv}{\\mathbf{d}}\n",
    "\\newcommand{\\Vv}{\\mathbf{V}}\n",
    "\\newcommand{\\vv}{\\mathbf{v}}\n",
    "\\newcommand{\\Uv}{\\mathbf{U}}\n",
    "\\newcommand{\\tv}{\\mathbf{t}}\n",
    "\\newcommand{\\Tv}{\\mathbf{T}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\Zv}{\\mathbf{Z}}\n",
    "\\newcommand{\\Zvh}{\\hat{\\mathbf{Z}}}\n",
    "\\newcommand{\\Ev}{\\mathbf{E}}\n",
    "\\newcommand{\\onev}{\\mathbf{1}}\n",
    "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}\n",
    "\\newcommand{\\dimensionbar}[1]{\\underset{#1}{\\operatorname{|}}}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2.4 Three-Layer Neural Network\n",
    "\n",
    "* A2.4: Now the output from Code Cell [11] is correct. I hadn't rerun it for A2.3.   \n",
    "* A2.3: One more fix to Code Cell [11], in how results are appended.\n",
    "* A2.2: The line `results.append([n_iterations, nh1, nh2, 'scg', result_scg['ftrace'][-1]])` has been corrected.  It had used `'sgd'` before.\n",
    "* A2.1: Replaced the diagram with one having more details. Modified the math equations for clarity. Added another example run showing the expected generality of your functions. A2grader.zip now available.\n",
    "* A2.0: the original assignment description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sarah Houlton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, we modify the two-layer neural network matrix equations and code from lecture notes to become a three-layer neural network, one with two hidden layers.  In the following diagram, you will be adding another layer on the left between in the inputs, $x$, and the show hiddden layer.\n",
    "\n",
    "You must complete three steps.\n",
    "1. Complete the matrix equations using latex notation in the markdown cell,\n",
    "2. Implement the required functions in python.\n",
    "3. Perform the described experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas\n",
    "import optimizers as opt  # from Lecture Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Diagram\n",
    "\n",
    "![Two Layers](http://www.cs.colostate.edu/~anderson/cs545/notebooks/net-A2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Equations\n",
    "\n",
    "Here are the matrix equations for a network with two hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "\\begin{align*}\n",
    "N &= \\text{ number of samples } \\\\\n",
    "I &= \\text{ the number of attributes in each sample }\\\\\n",
    "K &= \\text{ number of units in output layer } \\\\\n",
    "H_1 &= \\text{ number of units in first hidden layer }\\\\\n",
    "H_2 &= \\text{ number of units in second hidden layer }\\\\\n",
    "~\\\\\n",
    "\\Zv_1 &= \\tanh(\\Xvh\\, \\Uv) \\\\\n",
    "\\Zv_2 &= \\tanh(\\Zvh_1\\, \\Vv) \\\\\n",
    "\\Yv &= \\Zvh_2\\, \\Wv\\\\\n",
    "\\Ev &= \\frac{1}{NK} \\sum_{n=1}^N \\sum_{k=1}^K (\\Tv_{n,k} - \\Yv_{n,k})^2 \\\\\n",
    "~\\\\\n",
    "\\nabla_\\Yv E_{n,k} &= \\frac{-2}{NK} (\\Tv_{n,k} - \\Yv_{n,k})\\\\\n",
    "\\delta_\\Yv &= \\frac{-2}{NK} (\\Tv - \\Yv)\\\\\n",
    "\\nabla_\\Wv E &=  \\underbrace{\\underbrace{\\Zvh_2^T}_{H+1\\times N} \\underbrace{\\delta_\\Yv}_{N\\times K}}_{H+1\\times K}\\\\\n",
    "~\\\\\n",
    "\\nabla_\\Vv E &= \\underbrace{\\underbrace{\\Xvh^T}_{I+1\\times N} \\; \\underbrace{\\delta_{\\Zv_2}}_{N\\times H}}_{I+1\\times H} \\;\\;\\;\\;\\text{ where } \\delta_{\\Zv_2} = (\\delta_\\Yv \\; \\Wv_{1:}^T)\\; \\cdot\\; (1-\\Zv_2^2) \\;\\;\\;\\; \\text{ if } f(\\Xvh \\Vv) = \\tanh(\\Xvh \\Vv)\\\\\n",
    "\\nabla_\\Uv E &= \\underbrace{\\underbrace{\\Xvh^T}_{I+1\\times N} \\; \\underbrace{\\delta_{\\Zv_1}}_{N\\times H}}_{I+1\\times H} \\;\\;\\;\\;\\text{ where } \\delta_{\\Zv_1} = (\\delta_\\Yv \\; \\Wv_{1:}^T)\\; \\cdot\\; (1-\\Zv_1^2) \\;\\;\\;\\; \\text{ if } f(\\Xvh \\Vv) = \\tanh(\\Xvh \\Vv)\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "Modify the functions `network` `error_gradient` and `mse` to do the compuations for a three-layer neural network.  They must have the following arguments:\n",
    "* `Y = network(w, n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X, all_outputs=False)`\n",
    "or\n",
    "* `Y, Z1, Z2 = network(w, n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X, all_outputs=True)`\n",
    "* `gradient = error_gradient(w, n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X, T)`\n",
    "* `mean_squared_error = mse(w, n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X, T)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(w, n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X, all_outputs=False):\n",
    "    n_U = (n_inputs + 1) * n_hiddens_1\n",
    "    n_V = (n_hiddens_1 + 1) * n_hiddens_2\n",
    "    n_W = (n_inputs + 1)* (n_hiddens_1) + (n_hiddens_1 + 1)* n_hiddens_2 + (n_hiddens_2 + 1) * n_outputs\n",
    "    U = w[:n_U].reshape((n_inputs + 1, n_hiddens_1))\n",
    "    V = w[n_U: n_U + n_V].reshape((n_hiddens_1 + 1, n_hiddens_2))\n",
    "    W = w[n_U + n_V:].reshape((n_hiddens_2 + 1, n_outputs))\n",
    "    Z1 = np.tanh(U[0:1, :] + X @ U[1:, :])\n",
    "    Z2 = np.tanh(V[0:1, :] + Z1 @ V[1:, :])\n",
    "    \n",
    "    Y = W[0:1, :] + Z2 @ W[1:, :]\n",
    "    return (Y, Z1, Z2) if all_outputs else Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_gradient(w, n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X, T):\n",
    "    Y, Z1, Z2 = network(w, n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X, all_outputs=True)\n",
    "    n_samples = X.shape[0]\n",
    "    delta_Y = -2 / (n_samples * n_outputs) * (T - Y)\n",
    "    Z2_hat = np.insert(Z2, 0, 1, axis=1)\n",
    "    dEdW = Z2_hat.T @ delta_Y\n",
    "    \n",
    "    \n",
    "    n_W = (n_inputs + 1)* (n_hiddens_1) + (n_hiddens_1 + 1)* n_hiddens_2 + (n_hiddens_2 + 1) * n_outputs\n",
    "    print(delta_Y.shape, w[-n_W:].shape)\n",
    "    W = w[-n_W:].reshape((n_hiddens_2 + 1, n_outputs))\n",
    "    delta_Z1 = (delta_Y @ W[1:, :].T) * (1 - Z1**2)\n",
    "    delta_Z2 = (delta_Y @ W[1:, :].T) * (1 - Z2**2)\n",
    "    X_hat = np.insert(X, 0, 1, axis=1)\n",
    "    dEdV = X_hat.T @ delta_Z2\n",
    "    dEdU = X_hat.T @ delta_Z1\n",
    "    \n",
    "\n",
    "    dEdw = np.hstack((dEdU.flatten(), dEdV.flatten(), dEdW.flatten()))\n",
    "    return dEdw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method throws an error that I could never quite figure it out. It's coming from how I shape W, but I wasn't able to get it right before the deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse (w, n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X, T):\n",
    "    Y = network(w, n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X)\n",
    "    return np.mean((T - Y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(3 * 4).reshape((3, 4)) * 0.1\n",
    "T = np.hstack(( np.sin(X[:, 0:1]) + X[:, 1:2],\n",
    "                X[:, 2:3] * -0.5,\n",
    "                X[:, 3:4] ** 2))\n",
    "n_inputs = X.shape[1]\n",
    "n_outputs = T.shape[1]\n",
    "n_hiddens_1 = 6\n",
    "n_hiddens_2 = 2\n",
    "n_w = (n_inputs + 1) * n_hiddens_1 + (n_hiddens_1 + 1) * n_hiddens_2 + (n_hiddens_2 + 1) * n_outputs\n",
    "w = (np.arange(n_w) - n_w/2) * 0.01\n",
    "Y = network(w, n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X)\n",
    "Y, Z1, Z2 = network(w, n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X, all_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3) (53,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 53 into shape (19,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Documents\\Sarah\\Grad Comp Sci\\CS 545\\A2grader.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_hiddens_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_hiddens_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Sarah\\Grad Comp Sci\\CS 545\\A2grader.py\u001b[0m in \u001b[0;36merror_gradient\u001b[1;34m(w, n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X, T)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mn_W\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_inputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_hiddens_1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_hiddens_1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m \u001b[0mn_hiddens_2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_hiddens_2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta_Y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mn_W\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mn_W\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_hiddens_1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn_outputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mdelta_Z1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdelta_Y\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mZ1\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mdelta_Z2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdelta_Y\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mZ2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 53 into shape (19,3)"
     ]
    }
   ],
   "source": [
    "grad = error_gradient(w, n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X, T)\n",
    "grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Air Quality Data\n",
    "Use your code to, as before, predict CO from the Hour of the day.\n",
    "\n",
    "Set up the data matrices `X` and `T` as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape = (443, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[18. ,  2.6],\n",
       "       [19. ,  2. ],\n",
       "       [20. ,  2.2],\n",
       "       [21. ,  2.2],\n",
       "       [22. ,  1.6],\n",
       "       [23. ,  1.2],\n",
       "       [ 0. ,  1.2],\n",
       "       [ 1. ,  1. ],\n",
       "       [ 2. ,  0.9],\n",
       "       [ 3. ,  0.6]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv('AirQualityUCI.csv', delimiter=';', decimal=',', usecols=range(15), na_values=-200)\n",
    "data = data[['Time', 'CO(GT)']]\n",
    "data = data [:23 * 20]  # first 20 days of data\n",
    "data = data.dropna(axis=0)\n",
    "print('data.shape =', data.shape)\n",
    "\n",
    "hour = [int(t[:2]) for t in data['Time']]\n",
    "X = np.array(hour).reshape(-1, 1)\n",
    "CO = data['CO(GT)']\n",
    "T = np.array(CO).reshape(-1, 1)\n",
    "np.hstack((X, T))[:10]  # show the first 10 samples of hour, CO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the network parameters.  Use the shapes of `X` and `T` to assign the number of inputs and outputs.  Define each of the two hidden layers to have 5 units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = X.shape[1]\n",
    "n_hiddens_1 = 5\n",
    "n_hiddens_2 = 5\n",
    "n_outputs = T.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must define the intial weight vector.  The vector contains a value for each weight in all three layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_U = (n_inputs + 1) * n_hiddens_1\n",
    "n_V = (n_hiddens_1 + 1) * n_hiddens_2\n",
    "n_W = (n_hiddens_2 + 1) * n_outputs\n",
    "\n",
    "initial_w = np.random.uniform(-0.1, 0.1, n_U + n_V + n_W)  # range of weights is -0.1 to 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training our network, standardize the input values, to change the hour to have zero mean and unit variance across the set of samples.  Change `True` to `False` to not perform this step, allowing you to compare results with and without standardization.  It is not required to show the results here.  When you check in your notebook, leave `standardize` set to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X mean is 0.000 and its standard deviation is 1.000\n"
     ]
    }
   ],
   "source": [
    "standardize = True\n",
    "\n",
    "if standardize:\n",
    "    X_mean = X.mean(axis=0)\n",
    "    X_std = X.std(axis=0)\n",
    "    \n",
    "    X = (X - X_mean) / X_std\n",
    "    \n",
    "print(f'X mean is {X.mean(axis=0)[0]:.3f} and its standard deviation is {X.std(axis=0)[0]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train our network using each of our three optimization algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(443, 1) ()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 46 into shape (6,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Documents\\Sarah\\Grad Comp Sci\\CS 545\\A2grader.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m                      \u001b[0mmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_gradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_hiddens_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_hiddens_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                      \u001b[0mn_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_iterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                      save_wtrace=True)\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'SGD final error is {result_sgd[\"ftrace\"][-1]:.3f} and it took {result_sgd[\"time\"]:.2f} seconds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Sarah\\Grad Comp Sci\\CS 545\\optimizers.py\u001b[0m in \u001b[0;36msgd\u001b[1;34m(w, error_f, error_gradient_f, fargs, n_iterations, eval_f, learning_rate, momentum_rate, save_wtrace, verbose)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mfnow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# to calculate layer outputs for gradient calculation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_gradient_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mw_change\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgrad\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmomentum_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mw_change\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mw\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mw_change\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Sarah\\Grad Comp Sci\\CS 545\\A2grader.py\u001b[0m in \u001b[0;36merror_gradient\u001b[1;34m(w, n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X, T)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mn_W\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_inputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_hiddens_1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_hiddens_1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m \u001b[0mn_hiddens_2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_hiddens_2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta_Y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mn_W\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mn_W\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_hiddens_2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mdelta_Z1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdelta_Y\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mZ1\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mdelta_Z2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdelta_Y\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mZ2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 46 into shape (6,1)"
     ]
    }
   ],
   "source": [
    "n_iterations = 2000\n",
    "\n",
    "result_sgd = opt.sgd(initial_w,\n",
    "                     mse, error_gradient, fargs=[n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X, T],\n",
    "                     n_iterations=n_iterations, learning_rate=1e-1, momentum_rate=0.2, \n",
    "                     save_wtrace=True)\n",
    "print(f'SGD final error is {result_sgd[\"ftrace\"][-1]:.3f} and it took {result_sgd[\"time\"]:.2f} seconds')\n",
    "\n",
    "result_adam = opt.adam(initial_w, \n",
    "                       mse, error_gradient, fargs=[n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X, T],\n",
    "                       n_iterations=n_iterations, learning_rate=1e-2, \n",
    "                       save_wtrace=True)\n",
    "print(f'Adam final error is {result_adam[\"ftrace\"][-1]:.3f} and it took {result_adam[\"time\"]:.2f} seconds')\n",
    "\n",
    "result_scg = opt.scg(initial_w,\n",
    "                     mse, error_gradient, fargs=[n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X, T],\n",
    "                     n_iterations=n_iterations,\n",
    "                     save_wtrace=True)\n",
    "print(f'SCG final error is {result_scg[\"ftrace\"][-1]:.3f} and it took {result_scg[\"time\"]:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the error curve and the model fits for each of the optimization algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_sgd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Documents\\Sarah\\Grad Comp Sci\\CS 545\\A2grader.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_sgd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ftrace'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SGD'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_adam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ftrace'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Adam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_scg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ftrace'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SCG'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result_sgd' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(result_sgd['ftrace'], label='SGD')\n",
    "plt.plot(result_adam['ftrace'], label='Adam')\n",
    "plt.plot(result_scg['ftrace'], label='SCG')\n",
    "plt.legend()\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('MSE')\n",
    "plt.ylim(0, 4)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "if standardize:\n",
    "    plt.plot(X * X_std + X_mean, T, 'k.')  # unstandardize X\n",
    "else:\n",
    "    plt.plot(X, T, 'k.')\n",
    "xs = np.linspace(0, 23, 100).reshape((-1, 1))\n",
    "xs_standardized = (xs - X_mean) / X_std if standardize else xs\n",
    "plt.plot(xs, network(result_sgd['w'], n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, xs_standardized), label='SGD')\n",
    "plt.plot(xs, network(result_adam['w'], n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, xs_standardized), label='Adam')\n",
    "plt.plot(xs, network(result_scg['w'], n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, xs_standardized), label='SCG')\n",
    "plt.legend()\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('CO');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some code that tries a number of values for the key parameters of `n_iterations`, `n_hiddens_1`, `n_hiddens_2` and `learning_rate`.\n",
    "\n",
    "**Required:** Modify the lists of values in the four for loops to try other parameter values.  Try to find ranges that work well for all three algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for n_iterations in [10, 100]:\n",
    "    for nh1 in [1, 2]:\n",
    "        for nh2 in [1, 2]:\n",
    "            \n",
    "            n_U = (n_inputs + 1) * nh1\n",
    "            n_V = (nh1 + 1) * nh2\n",
    "            n_W = (nh2 + 1) * n_outputs\n",
    "            initial_w = np.random.uniform(-0.1, 0.1, n_U + n_V + n_W)\n",
    "\n",
    "            result_scg = opt.scg(initial_w, mse, error_gradient, fargs=[n_inputs, nh1, nh2, n_outputs, X, T],\n",
    "                                 n_iterations=n_iterations)\n",
    "            results.append([n_iterations, nh1, nh2, 0, 'scg', result_scg['ftrace'][-1]])\n",
    "            \n",
    "            for lr in [1e-3, 1e-5]:\n",
    "                \n",
    "                result_sgd = opt.sgd(initial_w, mse, error_gradient, fargs=[n_inputs, nh1, nh2, n_outputs, X, T],\n",
    "                     n_iterations=n_iterations, learning_rate=lr, momentum_rate=0)\n",
    "                result_adam = opt.adam(initial_w, mse, error_gradient, fargs=[n_inputs, nh1, nh2, n_outputs, X, T],\n",
    "                                       n_iterations=n_iterations, learning_rate=lr)\n",
    " \n",
    "                results.append([n_iterations, nh1, nh2, lr, 'sgd', result_sgd['ftrace'][-1]])\n",
    "                results.append([n_iterations, nh1, nh2, lr, 'adam', result_adam['ftrace'][-1]])\n",
    "\n",
    "results = pandas.DataFrame(results, columns=('Iterations', 'nh1', 'nh2', 'lr', 'algo', 'mse'))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required:** Show the results for the 20 lowest MSE values, sorted by increasing MSE. Read about the `sort_values` and `head` methods on a `DataFrame`.  You can do this with a single line of python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head(results.sort_values(ascending=False), n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you have cleverly written your code to handle any value of $I$, $H_1$, $H_2$, and $K$, your code should be able to handle the following data that contains three attributes for each of 5 samples and two output values for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(15).reshape((5, 3))\n",
    "T = np.hstack((X[:, 0:1] * 0.1 * X[:, 1:2], X[:, 2:]**2)) # making two target values for each sample\n",
    "T = T.reshape((5, 2))\n",
    "print('  Input            Target')\n",
    "for x, t in zip(X, T):\n",
    "    print(x, '\\t', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use your code to train a neural network with two hidden layers, having 50 units in the first hidden layer and 3 units in the second hidden layer.  This example does not perform the standardization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hiddens_1 = 50\n",
    "n_hiddens_2 = 3\n",
    "n_iterations = 1000\n",
    "\n",
    "\n",
    "n_inputs = X.shape[1]\n",
    "n_outputs = T.shape[1]\n",
    "\n",
    "n_U = (n_inputs + 1) * n_hiddens_1\n",
    "n_V = (n_hiddens_1 + 1) * n_hiddens_2\n",
    "n_W = (n_hiddens_2 + 1) * n_outputs\n",
    "\n",
    "initial_w = np.random.uniform(-0.1, 0.1, n_U + n_V + n_W)  # range of weights is -0.1 to 0.1\n",
    "\n",
    "result_sgd = opt.sgd(initial_w,\n",
    "                     mse, error_gradient, fargs=[n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X, T],\n",
    "                     n_iterations=n_iterations, learning_rate=1e-1, momentum_rate=0.2, \n",
    "                     save_wtrace=True)\n",
    "print(f'SGD final error is {result_sgd[\"ftrace\"][-1]:.3f} and it took {result_sgd[\"time\"]:.2f} seconds')\n",
    "\n",
    "result_adam = opt.adam(initial_w, \n",
    "                       mse, error_gradient, fargs=[n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X, T],\n",
    "                       n_iterations=n_iterations, learning_rate=1e-2, \n",
    "                       save_wtrace=True)\n",
    "print(f'Adam final error is {result_adam[\"ftrace\"][-1]:.3f} and it took {result_adam[\"time\"]:.2f} seconds')\n",
    "\n",
    "result_scg = opt.scg(initial_w,\n",
    "                     mse, error_gradient, fargs=[n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X, T],\n",
    "                     n_iterations=n_iterations,\n",
    "                     save_wtrace=True)\n",
    "print(f'SCG final error is {result_scg[\"ftrace\"][-1]:.3f} and it took {result_scg[\"time\"]:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = result_scg['w']\n",
    "\n",
    "Y = network(w, n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diagonal(T, Y):\n",
    "    a = min(T.min(), Y.min())\n",
    "    b = max(T.max(), Y.max())\n",
    "    plt.plot([a, b], [a, b], '-', lw=3, alpha=0.5)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(result_scg['ftrace'])\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('SCG')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(T[:, 0], Y[:, 0], '.')\n",
    "plot_diagonal(T[:, 0], Y[:, 0])\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Prediction')\n",
    "plt.title('$Y_1$')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(T[:, 1], Y[:, 1], '.')\n",
    "plot_diagonal(T[:, 1], Y[: 1])\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Prediction')\n",
    "plt.title('$Y_2$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================= Code Execution =======================\n",
      "\n",
      "Extracting python code from notebook named 'Houlton-A2.ipynb' and storing in notebookcode.py\n",
      "Removing all statements that are not function or class defs or import statements.\n",
      "\n",
      "Testing\n",
      "X = np.arange(3 * 4).reshape((3, 4)) * 0.1\n",
      "T = np.hstack(( np.sin(X[:, 0:1]) + X[:, 1:2],\n",
      "                X[:, 2:3] * -0.5,\n",
      "                X[:, 3:4] ** 2))\n",
      "n_inputs = X.shape[1]\n",
      "n_outputs = T.shape[1]\n",
      "n_hiddens_1 = 6\n",
      "n_hiddens_2 = 2\n",
      "n_w = (n_inputs + 1) * n_hiddens_1 + (n_hiddens_1 + 1) * n_hiddens_2 + (n_hiddens_2 + 1) * n_outputs\n",
      "w = (np.arange(n_w) - n_w/2) * 0.01\n",
      "Y = network(w, n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X)\n",
      "\n",
      "\n",
      "--- 20/20 points. Returned correct values.\n",
      "\n",
      "Testing\n",
      "Y, Z1, Z2 = network(w, n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X, all_outputs=True)\n",
      "\n",
      "\n",
      "--- 20/20 points. Returned correct values.\n",
      "\n",
      "Testing\n",
      "grad = error_gradient(w, n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X, T)\n",
      "\n",
      "\n",
      "--- 0/20 points. network raised the exception\n",
      "\n",
      "cannot reshape array of size 53 into shape (3,3)\n",
      "\n",
      "Testing\n",
      "m = mse(w, n_inputs, n_hiddens_1, n_hiddens_2, n_outputs, X, T)\n",
      "\n",
      "\n",
      "--- 20/20 points. Returned correct values.\n",
      "\n",
      "C:\\Users\\Sarah\\Documents\\Sarah\\Grad Comp Sci\\CS 545 Execution Grade is 60 / 80\n",
      "\n",
      "Your final assignment grade will be based on other tests.  Run additional tests\n",
      "of your own design to check your functions before checking in this notebook.\n",
      "\n",
      "C:\\Users\\Sarah\\Documents\\Sarah\\Grad Comp Sci\\CS 545 FINAL GRADE is ___ / 100\n"
     ]
    }
   ],
   "source": [
    "%run -i A2grader.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
